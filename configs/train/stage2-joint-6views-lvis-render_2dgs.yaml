pretrained_model_name_or_path: 'lambdalabs/sd-image-variations-diffusers'
# modify the unet path; use the stage 1 checkpoint
# pretrained_unet_path: '/home/xuyimeng/Repo/Wonder3D/outputs/splatter/wonder3D-mix-128-lara-splatter-lmdb-4gpus/checkpoint-run5-13500'
pretrained_unet_path: 'outputs/splatter/wonder3D-joint-128-lara_splatter-rope-ZERO_SNR-BSZ16_acc1_gpu4-all_trainable/checkpoint-20k'
# pretrained_decoder_path: '/mnt/kostas_home/lilym/LGM/LGM/runs/finetune_decoder/workspace_train_sep/00008-LARA_DATA-sd_decoder-2dgs-GT_normal_loss_foreground-resume8800-numV15-loss_render1.0_splatter1.0_lpips2.0-lr5e-06-Plat5/eval_global_step_8000_ckpt/model.safetensors'
pretrained_decoder_path: null
revision: null
rendering_loss_2dgs: false
train_dataset:
  root_dir: '/mnt/kostas-graid/datasets/xuyimeng/GobjLara/dataset/gobjaverse/gobjaverse.h5'  # change to your path
  object_list: './data_lists/single_obj.json'
  invalid_list: './data_lists/lvis_invalid_uids_nineviews.json'
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  # img_wh: [256, 256]
  img_wh: [128, 128] # fast dev
  validation: false
  num_validation_samples: 4
  read_normal: true
  read_color: true
  overfit: false
  debug: false
  lmdb_6view_base: '/mnt/kostas-graid/datasets/xuyimeng/lara/lmdb_database_1views_whole_HASHED/lmdb_database'
  rendering_loss_2dgs: false # ${rendering_loss_2dgs} 
  read_first_view_only: true
  render_views: 10
validation_dataset:
  root_dir: ${train_dataset.root_dir}  # change to your path
  object_list: './data_lists/single_obj.json'
  invalid_list: './data_lists/lvis_invalid_uids_nineviews.json'
  num_views: 6
  groups_num: 1
  bg_color: 'white'
  img_wh: ${train_dataset.img_wh}
  validation: true
  num_validation_samples: 4
  read_normal: true
  read_color: true
  overfit: ${train_dataset.overfit}
  debug: ${train_dataset.debug}
  lmdb_6view_base: ${train_dataset.lmdb_6view_base}
  rendering_loss_2dgs: ${rendering_loss_2dgs} 
  read_first_view_only: false # ${train_dataset.read_first_view_only}
  render_views: 20 # ${train_dataset.render_views}
validation_train_dataset:
  root_dir: ${train_dataset.root_dir}  # change to your path
  object_list: './data_lists/single_obj.json'
  invalid_list: './data_lists/lvis_invalid_uids_nineviews.json'
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  img_wh: ${train_dataset.img_wh}
  validation: false
  num_validation_samples: 4 # 32
  num_samples: 32
  read_normal: true
  read_color: true
  overfit: ${train_dataset.overfit}
  debug: ${train_dataset.debug}
  lmdb_6view_base: ${train_dataset.lmdb_6view_base}
  rendering_loss_2dgs: ${rendering_loss_2dgs} 
  read_first_view_only: false # ${train_dataset.read_first_view_only}
  render_views: ${train_dataset.render_views}

# output_dir:  'outputs/splatter/wonder3D-joint-128-lara_splatter-BSZ4_acc1_1gpu-DEBUG-2DGS-OVERFIT'
output_dir:  'outputs/splatter/wonder3D-joint-128-lara_splatter-NO_rope_domainXY_ids-all_trainable-BSZ16_acc2_gpu2'
# output_dir:  'outputs/splatter/wonder3D-joint-128-lara_splatter-rope-ZERO_SNR-BSZ16_acc1_gpu4-all_trainable' # todo: add checkpoint folders
# output_dir:  'outputs/debug/BSZ2_acc1-all_trainable-OVERFIT-DBBUG_zeroSNR'

seed: 42
train_batch_size: 16 # original paper uses 32
validation_batch_size: 2 # use 1 for gassian reconstruction ${train_batch_size} # 16
validation_train_batch_size: 16
max_train_steps: 20000
gradient_accumulation_steps: 2
gradient_checkpointing: true
learning_rate: 5.e-5
scale_lr: false
lr_scheduler: "constant_with_warmup"
lr_warmup_steps: 100
snr_gamma: 5.0
use_8bit_adam: false
allow_tf32: true
use_ema: true  
dataloader_num_workers: 8 # 64
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
max_grad_norm: 1.0
prediction_type: null
vis_dir: vis
logging_dir: logs
mixed_precision: "fp16"
report_to: 'tensorboard'
local_rank: -1
checkpointing_steps: 2000
checkpoints_total_limit: null
last_global_step: 0

# resume_from_checkpoint: /home/xuyimeng/Repo/Wonder3D/outputs/splatter/wonder3D-joint-128-lara_splatter-ROPE_domainXY_ids-BSZ16_acc2_gpu2-all_trainable/checkpoint-run2
resume_from_checkpoint: latest
enable_xformers_memory_efficient_attention: true
validation_steps: 1000
validation_sanity_check: true
tracker_project_name: 'mvdiffusion-image-v1'

trainable_modules: null
# trainable_modules: ['joint_mid']
use_classifier_free_guidance: true
condition_drop_rate: 0.05
drop_type: 'drop_as_a_whole'  # modify
camera_embedding_lr_mult: 10.
scale_input_latents: true

pipe_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  num_views: 6

validation_guidance_scales: [1., 3., 0.]
pipe_validation_kwargs:
  eta: 1.0
validation_grid_nrow: 10

unet_from_pretrained_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  projection_class_embeddings_input_dim: 16  # modify: 10 for 2 domains
  num_views: 6
  sample_size: 16 # when im_hw=128
  zero_init_conv_in: false
  zero_init_camera_projection: false
  cd_attention_last: false
  cd_attention_mid: true
  multiview_attention: true
  sparse_mv_attention: false
  mvcd_attention: false
  low_cpu_mem_usage: false # added to load ckpt 

num_views: 6
camera_embedding_type: 'e_de_da_sincos'
zero_terminal_snr: true
sync_domain_timesteps: false

