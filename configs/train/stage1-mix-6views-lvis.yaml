pretrained_model_name_or_path: 'lambdalabs/sd-image-variations-diffusers'
revision: null
train_dataset:
  root_dir: '/mnt/kostas-graid/datasets/xuyimeng/GobjLara/dataset/gobjaverse/gobjaverse.h5'  # change to your path
  object_list: './data_lists/single_obj.json'
  invalid_list: './data_lists/lvis_invalid_uids_nineviews.json'
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  # img_wh: [256, 256]
  img_wh: [128, 128] # fast dev
  validation: false
  num_validation_samples: 32  
  # read_normal: true
  # read_color: true
  mix_color_normal: true
  read_mask: false
  overfit: true
validation_dataset:
  root_dir: ${train_dataset.root_dir}  # change to your path
  object_list: './data_lists/single_obj.json'
  invalid_list: './data_lists/lvis_invalid_uids_nineviews.json'
  num_views: 6
  groups_num: 1
  bg_color: 'white'
  img_wh: ${train_dataset.img_wh}
  validation: true
  num_validation_samples: 32
  # read_normal: true
  # read_color: true
  mix_color_normal: true
  read_mask: false
  overfit: ${train_dataset.overfit}
validation_train_dataset:
  root_dir: ${train_dataset.root_dir}  # change to your path
  object_list: './data_lists/single_obj.json'
  invalid_list: './data_lists/lvis_invalid_uids_nineviews.json'
  num_views: 6
  groups_num: 1
  bg_color: 'white'
  img_wh: ${train_dataset.img_wh}
  validation: false
  num_validation_samples: 32
  num_samples: 32
  # read_normal: true
  # read_color: true
  mix_color_normal: true
  read_mask: false
  overfit: ${train_dataset.overfit}

pred_type: 'mix'

output_dir: 'outputs/overfit/wonder3D-mix-128-lara-splatter_pos_rgb'
seed: 42
train_batch_size: 16
validation_batch_size: ${train_batch_size} # 16
validation_train_batch_size: 16
max_train_steps: 30000
gradient_accumulation_steps: 1
gradient_checkpointing: false
learning_rate: 1.e-4
scale_lr: false
lr_scheduler: "constant_with_warmup"
lr_warmup_steps: 100
snr_gamma: 5.0
use_8bit_adam: false
allow_tf32: true
use_ema: true  
dataloader_num_workers: 4 #  64
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
max_grad_norm: 1.0
prediction_type: null
vis_dir: vis
logging_dir: logs
mixed_precision: "fp16"
report_to: 'tensorboard'
local_rank: -1
checkpointing_steps: 200
checkpoints_total_limit: 20
resume_from_checkpoint: latest
enable_xformers_memory_efficient_attention: true
validation_steps: 200
validation_sanity_check: true
tracker_project_name: 'mvdiffusion-image-v1'

trainable_modules: null
use_classifier_free_guidance: true
condition_drop_rate: 0.05
drop_type: 'drop_as_a_whole'  # modify
camera_embedding_lr_mult: 10.
scale_input_latents: true

pipe_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  num_views: 6
  num_tasks: 2

validation_guidance_scales: [1., 3.]
pipe_validation_kwargs:
  eta: 1.0
validation_grid_nrow: 12

unet_from_pretrained_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  projection_class_embeddings_input_dim: 10 # modify: 10 for normal & color
  num_views: 6
  sample_size: 16 # 32
  zero_init_conv_in: true
  zero_init_camera_projection: false
  cd_attention_last: false
  cd_attention_mid: false
  multiview_attention: true
  sparse_mv_attention: false
  mvcd_attention: false

num_views: 6
camera_embedding_type: 'e_de_da_sincos'
